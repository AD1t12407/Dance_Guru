{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m mp_pose \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mpose\n\u001b[1;32m      6\u001b[0m pose \u001b[38;5;241m=\u001b[39m mp_pose\u001b[38;5;241m.\u001b[39mPose()\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/tasks/python/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/tasks/python/audio/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m \u001b[43maudio_classifier\u001b[49m\u001b[38;5;241m.\u001b[39mAudioClassifier\n\u001b[1;32m     22\u001b[0m AudioClassifierOptions \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierOptions\n\u001b[1;32m     23\u001b[0m AudioClassifierResult \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierResult\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def extract_keypoints(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    guru_keypoints = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop when video ends\n",
    "\n",
    "        # Convert frame to RGB for processing\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(img_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = [(lm.x, lm.y) for lm in results.pose_landmarks.landmark]\n",
    "            guru_keypoints.append(keypoints)\n",
    "\n",
    "    cap.release()\n",
    "    np.save(\"guru_poses.npy\", guru_keypoints)  # Save for future comparisons\n",
    "\n",
    "# Run the function on your Guru's video\n",
    "extract_keypoints(\"/Users/aditinarayan/Desktop/Computer_vision/trimmed_video.mp4\")\n",
    "print(\"âœ… Guru's keypoints saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738565097.749482 1654760 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "W0000 00:00:1738565097.906529 1690724 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738565097.926683 1690727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-02-03 12:15:47.108 python[54387:1654760] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-02-03 12:15:47.108 python[54387:1654760] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Show the frame\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent vs Guru\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     46\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Track student poses over time\n",
    "student_keypoints_sequence = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame for a better user experience\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB (MediaPipe expects RGB)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the frame to detect the student's pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        # Extract keypoints (x, y coordinates)\n",
    "        student_keypoints = [(lm.x, lm.y) for lm in results.pose_landmarks.landmark]\n",
    "        \n",
    "        # Store the student's keypoints sequence (for DTW)\n",
    "        student_keypoints_sequence.append(student_keypoints)\n",
    "\n",
    "        # Display the student's pose landmarks on the frame\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Student vs Guru\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastdtw\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fastdtw\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtasks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m framework\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m gpu\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/tasks/python/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n",
      "File \u001b[0;32m~/Desktop/Computer_vision/cvenc/lib/python3.10/site-packages/mediapipe/tasks/python/audio/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_classifier\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_embedder\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m AudioClassifier \u001b[38;5;241m=\u001b[39m \u001b[43maudio_classifier\u001b[49m\u001b[38;5;241m.\u001b[39mAudioClassifier\n\u001b[1;32m     22\u001b[0m AudioClassifierOptions \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierOptions\n\u001b[1;32m     23\u001b[0m AudioClassifierResult \u001b[38;5;241m=\u001b[39m audio_classifier\u001b[38;5;241m.\u001b[39mAudioClassifierResult\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Initialize Pose Estimation Model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Load Guruâ€™s Pre-recorded Video\n",
    "guru_video_path = \"/Users/aditinarayan/Desktop/Computer_vision/trimmed_video.mp4\"\n",
    "guru_video = cv2.VideoCapture(guru_video_path)\n",
    "\n",
    "# Load Guruâ€™s Pose Data (Pre-extracted)\n",
    "guru_poses = np.load(\"/Users/aditinarayan/Desktop/Computer_vision/guru_poses.npy\", allow_pickle=True)\n",
    "\n",
    "# Initialize Webcam for Student\n",
    "student_cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Get Guru video dimensions\n",
    "guru_width = int(guru_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "guru_height = int(guru_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while student_cam.isOpened() and guru_video.isOpened():\n",
    "    # Read Guru's video frame\n",
    "    ret_guru, guru_frame = guru_video.read()\n",
    "    if not ret_guru:\n",
    "        guru_video.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Restart Guruâ€™s Video\n",
    "        continue\n",
    "\n",
    "    # Read Student's live video frame\n",
    "    ret_student, student_frame = student_cam.read()\n",
    "    if not ret_student:\n",
    "        break\n",
    "\n",
    "    # Convert student frame to RGB (for MediaPipe)\n",
    "    rgb_student_frame = cv2.cvtColor(student_frame, cv2.COLOR_BGR2RGB)\n",
    "    student_results = pose.process(rgb_student_frame)\n",
    "\n",
    "    # Extract student keypoints if detected\n",
    "    student_keypoints = None\n",
    "    if student_results.pose_landmarks:\n",
    "        student_keypoints = [(lm.x, lm.y) for lm in student_results.pose_landmarks.landmark]\n",
    "\n",
    "        # Ensure Guru & Student Keypoints are of same length before DTW\n",
    "        if len(student_keypoints) == len(guru_poses[0]):\n",
    "            distance, _ = fastdtw(student_keypoints, guru_poses[0], dist=euclidean)\n",
    "            similarity_score = max(0, 100 - distance)  # Normalize to 0-100%\n",
    "        else:\n",
    "            similarity_score = 0  # Default score if shape mismatch\n",
    "\n",
    "        # Draw Student's pose landmarks\n",
    "        mp_drawing.draw_landmarks(student_frame, student_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display Score\n",
    "        cv2.putText(student_frame, f\"Score: {int(similarity_score)}%\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Resize both frames to match Guruâ€™s video size\n",
    "    student_frame = cv2.resize(student_frame, (guru_width, guru_height))\n",
    "    guru_frame = cv2.resize(guru_frame, (guru_width, guru_height))\n",
    "\n",
    "    # Combine the two frames horizontally\n",
    "    combined_frame = np.hstack((guru_frame, student_frame))\n",
    "\n",
    "    # Show the combined frame\n",
    "    cv2.imshow(\"Guru vs Student\", combined_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "student_cam.release()\n",
    "guru_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
